{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:125: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [0], Loss: 0.4653, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [1], Loss: 0.3793, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [2], Loss: 0.3529, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [3], Loss: 0.4663, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [4], Loss: 0.5352, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [5], Loss: 0.5554, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [6], Loss: 0.4997, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [7], Loss: 0.5785, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [8], Loss: 0.6156, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [9], Loss: 0.6211, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [10], Loss: 0.6116, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [11], Loss: 0.5697, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [12], Loss: 0.5153, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [13], Loss: 0.5174, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [14], Loss: 0.4961, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [15], Loss: 0.5426, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [16], Loss: 0.6340, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [17], Loss: 0.5769, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [18], Loss: 0.5731, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [19], Loss: 0.6049, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [20], Loss: 0.5485, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [21], Loss: 0.5421, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [22], Loss: 0.5522, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [23], Loss: 0.5717, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [24], Loss: 0.5604, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [25], Loss: 0.5502, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [26], Loss: 0.5440, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [27], Loss: 0.5462, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [28], Loss: 0.5668, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [29], Loss: 0.5653, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [30], Loss: 0.5624, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [31], Loss: 0.5600, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [32], Loss: 0.5599, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [33], Loss: 0.5538, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [34], Loss: 0.5489, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [35], Loss: 0.5450, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n",
      "8280.0\n",
      "13457.0\n",
      "661.0\n",
      "1199.0\n",
      "Epoch [36], Loss: 0.5363, Train accuracy: 0.6153, Test accuracy: 0.5513, Best: 0.5513\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import csv\n",
    "from PIL import Image as PImage\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CD_Dataset(data.Dataset):\n",
    "    def __init__(self, src, path_csv, label_csv, transform=None):\n",
    "        with open(path_csv, 'r') as f:\n",
    "            path_reader = csv.reader(f)\n",
    "            p_list = list(path_reader)\n",
    "           \n",
    "        with open(label_csv, 'r') as f:\n",
    "            label_reader = csv.reader(f)\n",
    "            l_list = list(label_reader)\n",
    "\n",
    "        self.labels = []\n",
    "        self.pathes = []\n",
    "\n",
    "        for i in range(len(p_list)):\n",
    "            self.pathes.append(*p_list[i])\n",
    "            self.pathes[i] = src + self.pathes[i]\n",
    "            #print(self.pathes[i])\n",
    "        for i in range(len(l_list)):\n",
    "            self.labels.append(*l_list[i][1])\n",
    "    \n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.pathes[idx]\n",
    "        category = self.labels[idx]\n",
    "        image = PImage.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        category = np.array(category)\n",
    "        category = category.astype(np.int)\n",
    "        category = torch.from_numpy(category)\n",
    "        return image, category\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def score_predict(model, x):\n",
    "    batch_size = x.size(0)\n",
    "    score = model(x)\n",
    "    score = F.softmax(score, dim=1)\n",
    "    _,prediction = score.max(1)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def accuracy(iter, model):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in iter:\n",
    "            images = Variable(images).cuda()\n",
    "            preds = score_predict(model, images)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds.cpu().data == labels).sum().item()\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "img_path = '/home/ubuntu/MURA/MURA-v1.1/train_image_paths.csv'\n",
    "label_path = '/home/ubuntu/MURA/MURA-v1.1/train_labeled_studies.csv'\n",
    "imgval_path = '/home/ubuntu/MURA/MURA-v1.1/valid_image_paths.csv'\n",
    "labelval_path = '/home/ubuntu/MURA/MURA-v1.1/valid_labeled_studies.csv'\n",
    "src = '/home/ubuntu/MURA/'\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "transform_image = transforms.Compose([\n",
    "        transforms.Resize ([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "batchsize = 64\n",
    "epouch = 90\n",
    "learning_rate = 0.1\n",
    "best_result = 0\n",
    "\n",
    "MURA_dataset_train = CD_Dataset(src,img_path, label_path,transform=transform_image)\n",
    "MURA_dataset_test = CD_Dataset(src,imgval_path, labelval_path,transform=transform_image)\n",
    "MURA_trainloader = data.DataLoader(MURA_dataset_train, batch_size=batchsize)\n",
    "MURA_testloader = data.DataLoader(MURA_dataset_test, batch_size=batchsize)\n",
    "\n",
    "num_batch = len(MURA_trainloader)\n",
    "\n",
    "resNet = resnet18()\n",
    "resNet.cuda()\n",
    "\n",
    "params = [\n",
    "    {'params': resNet.parameters()}\n",
    "]\n",
    "\n",
    "optimizer = optim.SGD(params, lr=learning_rate, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for e in range(epouch):\n",
    "    resNet.train()\n",
    "    running_loss = 0.0\n",
    "    for x_batch, y_batch in MURA_trainloader:\n",
    "        \n",
    "        #y_batch = torch.from_numpy(y_batch)\n",
    "        x_batch, y_batch = Variable(x_batch.cuda()), Variable(y_batch.cuda(async=True))\n",
    "        prediction = resNet(x_batch)\n",
    "        \n",
    "        loss = criterion(prediction, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss = loss.data[0]        \n",
    "        running_loss += batch_loss\n",
    "\n",
    "\n",
    "    resNet.eval()\n",
    "\n",
    "    train_accuracy = accuracy(MURA_trainloader, resNet)\n",
    "    test_accuracy = accuracy(MURA_testloader, resNet)\n",
    "    \n",
    "    resNet.train()\n",
    "    if(test_accuracy>=best_result):\n",
    "        best_result = test_accuracy\n",
    "\n",
    "    print('Epoch [%d], Loss: %.4f, Train accuracy: %.4f, Test accuracy: %.4f, Best: %.4f' % (e, running_loss/num_batch, train_accuracy, test_accuracy, best_result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
